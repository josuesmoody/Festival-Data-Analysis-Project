{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01_data_collection.ipynb\n",
    "\n",
    "# Importación de bibliotecas\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "# Función para hacer scraping de Rock Werchter\n",
    "def scrape_rock_werchter():\n",
    "    \"\"\"\n",
    "    Scrapes historical lineup data from Rock Werchter festival.\n",
    "    Returns a DataFrame with year, artist, and festival information.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.rockwerchter.be/en/history\"\n",
    "    festival_data = []\n",
    "\n",
    "    try:\n",
    "        # Configura las opciones para el navegador (Chrome) en modo headless\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')  # Para ejecutar sin abrir una ventana del navegador\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        driver.get(base_url)\n",
    "\n",
    "        # Espera hasta que la sección con los festivales esté cargada\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"history-list\"))\n",
    "        )\n",
    "\n",
    "        # Obtén el contenido HTML de la página\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        # Encuentra las secciones que contienen los festivales por año\n",
    "        year_sections = soup.find_all('div', class_='history-item')\n",
    "\n",
    "        for section in year_sections:\n",
    "            # Extrae el año del festival\n",
    "            year = section.find('h2').text.strip()\n",
    "            \n",
    "            # Encuentra todos los artistas en la sección\n",
    "            artists = section.find_all('li')\n",
    "\n",
    "            for artist in artists:\n",
    "                festival_data.append({\n",
    "                    'festival': 'Rock Werchter',\n",
    "                    'year': int(year),\n",
    "                    'artist': artist.text.strip(),\n",
    "                    'source': base_url\n",
    "                })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping Rock Werchter: {str(e)}\")\n",
    "    finally:\n",
    "        # Asegúrate de cerrar el driver para liberar recursos\n",
    "        driver.quit()\n",
    "\n",
    "    # Devuelve los datos en un DataFrame de pandas\n",
    "    return pd.DataFrame(festival_data)\n",
    "\n",
    "# Función para hacer scraping de Pukkelpop\n",
    "def scrape_pukkelpop():\n",
    "    \"\"\"\n",
    "    Scrapes historical lineup data from Pukkelpop festival.\n",
    "    Returns a DataFrame with year, artist, and festival information.\n",
    "    \"\"\"\n",
    "    base_url = \"https://www.pukkelpop.be/en/history\"\n",
    "    festival_data = []\n",
    "\n",
    "    try:\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--headless')  # Sin interfaz gráfica (ideal para servidores)\n",
    "        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "        driver.get(base_url)\n",
    "\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"history-list\"))\n",
    "        )\n",
    "\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        year_sections = soup.find_all('div', class_='history-year')\n",
    "\n",
    "        for section in year_sections:\n",
    "            year = section.find('h2').text.strip()\n",
    "            artists = section.find_all('li')\n",
    "\n",
    "            for artist in artists:\n",
    "                festival_data.append({\n",
    "                    'festival': 'Pukkelpop',\n",
    "                    'year': int(year),\n",
    "                    'artist': artist.text.strip(),\n",
    "                    'source': base_url\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping Pukkelpop: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return pd.DataFrame(festival_data)\n",
    "\n",
    "# Función principal\n",
    "def main():\n",
    "    print(\"Scraping Rock Werchter data...\")\n",
    "    werchter_df = scrape_rock_werchter()\n",
    "\n",
    "    print(\"Scraping Pukkelpop data...\")\n",
    "    pukkelpop_df = scrape_pukkelpop()\n",
    "\n",
    "    # Combinar datos\n",
    "    all_festivals_df = pd.concat([werchter_df, pukkelpop_df], ignore_index=True)\n",
    "\n",
    "    # Guardar los datos recolectados\n",
    "    all_festivals_df.to_csv('../data/festival_data_raw.csv', index=False)\n",
    "    all_festivals_df.to_json('../data/festival_data_raw.json', orient='records')\n",
    "\n",
    "    print(\"Data collection complete!\")\n",
    "    return all_festivals_df\n",
    "\n",
    "# Ejecutar función principal\n",
    "if __name__ == \"__main__\":\n",
    "    festival_data = main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
